{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a14f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #for mathematical computation\n",
    "import matplotlib.pyplot as plt #for plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "3361e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z)) #sigmoid function = 1/(1+exp(-z))\n",
    "    cache = Z  \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):    \n",
    "    A = np.maximum(0,Z)  #Relu function = max(0, Z)\n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.   \n",
    "    dZ[Z <= 0] = 0   \n",
    "    return dZ\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "f1a28a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W):\n",
    "    Z = np.dot(A, W.T)  # Z = X.Transpose(W)\n",
    "    cache = (A, W)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "6e5c611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W) # This \"linear_cache\" contains (A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z) # This \"activation_cache\" contains \"Z\"\n",
    "\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W) # This \"linear_cache\" contains (A_prev, W, b)\n",
    "        A, activation_cache = relu(Z) # This \"activation_cache\" contains \"Z\"\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "87b30dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "5c658c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):            #AL = Predicted value, Y = True Value\n",
    "    m = Y.shape[1]                  #using mean square error to compute the loss\n",
    "    cost = np.square(Y - AL).mean() #means square error = 1/2*(y-AL)**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "bb8f7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    # Here cache is \"linear_cache\" containing (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    A_prev, W= cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m) * np.dot(dZ.T, A_prev)  #dL/dw = dl/dz*output_from_previous_neurons, where L is cost function\n",
    "    dA_prev = np.dot(dZ, W)      #dl/la_prev  = dl/dz* W    \n",
    "    \n",
    "    return dA_prev, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "54d43fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "      \n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "    \n",
    "    dA_prev, dW = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    \n",
    "    return dA_prev, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "2b6b886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "     # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "\n",
    "    dAL = AL-Y\n",
    "\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "\n",
    "    current_cache = caches[L-1] # Last Layer\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)] = linear_activation_backward(dAL, current_cache, \"relu\")\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp= linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "id": "2fe728f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "   \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbe5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    def __init__(self, lst=[]):\n",
    "        self.lst = lst\n",
    "        \n",
    "        self.parameters = {} #to store wieghts\n",
    "        \n",
    "        self.no_layer = len(self.lst) #no. of total layers in the network\n",
    "        \n",
    "        print(self.no_layer)\n",
    "        \n",
    "        self.hidden_layers = self.lst[1:-1] #total number of hidden layes in the network\n",
    "        \n",
    "        self.layer_dims = [lst[-1]] #initializing list which store ecah layer dimensions\n",
    "        \n",
    "        self.batch_size = 2 #batch size\n",
    "        \n",
    "        self.learning_rate = 0.1 #learning rate\n",
    "        \n",
    "        for hidden in self.hidden_layers:\n",
    "            self.layer_dims.append(hidden)\n",
    "            \n",
    "        self.layer_dims.append(lst[-1])\n",
    "                           \n",
    "        for l in range(1, self.no_layer): # initializing weights for each layers\n",
    "            self.parameters['W' + str(l)] = np.random.randn(self.layer_dims[l], self.layer_dims[l-1])*0.1\n",
    "#         print(self.parameters[\"W1\"].shape)\n",
    "#         print(self.parameters[\"W2\"].shape)\n",
    "#         print(self.parameters[\"W3\"].shape)\n",
    "        \n",
    "\n",
    " \n",
    "\n",
    "    def feed_forward(self,example):\n",
    "\n",
    "#        \"forward propagation\"\n",
    "        caches = [] # to store all linear and activation results \n",
    "        A = example\n",
    "        L = len(self.parameters)  \n",
    " \n",
    "        \n",
    "     # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    \n",
    "        for l in range(1, L):\n",
    "            \n",
    "            A_prev = A \n",
    "            \n",
    "            A, cache = linear_activation_forward(A_prev, self.parameters['W' + str(l)], \"relu\") #output from hidden layers\n",
    "            \n",
    "            caches.append(cache)\n",
    "    \n",
    "     # Implement LINEAR -> RELU. Add \"cache\" to the \"caches\" list.\n",
    "        AL, cache = linear_activation_forward(A, self.parameters['W' + str(L)],  \"relu\") #output from output layers\n",
    "        \n",
    "        caches.append(cache) \n",
    "     \n",
    "        feed_forward_op = AL, caches\n",
    "\n",
    "        return feed_forward_op\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "    def batch_sgd_backprop(self,X,Y):\n",
    "\n",
    "#        \"X-input array\"\n",
    "        self.X = X\n",
    "#        \"Y-output array\"\n",
    "        self.Y = Y\n",
    "\n",
    "        loss_list = [] #keep track of cost for every epoch\n",
    "        for epoch in range(0,100): #training for 100 epochs\n",
    "            mini_batches = iterate_minibatches(X, Y, self.batch_size) # creating batch for X and Y\n",
    "            loss = 0 #initialize loss = 0 for every epoch\n",
    "            for batch in mini_batches:\n",
    "                X_batch, Y_batch = batch\n",
    "              \n",
    "                feed_forward_op = self.feed_forward(X_batch) #getting forward propagation results\n",
    "#                 print(feed_forward_op[0])\n",
    "                AL, caches = feed_forward_op\n",
    "    \n",
    "                cost = compute_cost(AL, Y_batch) # computing the cost from output and true output value\n",
    "        \n",
    "                grads = L_model_backward(AL, Y_batch, caches) #calculating the gradients by back propagation\n",
    "#                 \"Update weights\"\n",
    "                self.parameters = update_parameters(self.parameters, grads, self.learning_rate) #updating the weights\n",
    "                \n",
    "                loss += cost #update loss = loss + cost\n",
    "                \n",
    "            print(\"loss after {} : {}\".format(epoch, loss))\n",
    "            \n",
    "            loss_list.append(loss) #append the loss\n",
    " \n",
    "           #plotting the graph between loss and epochs\n",
    "        plt.plot(np.squeeze(loss_list))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per epoch)')\n",
    "        plt.title(\"Learning rate =\" + str(self.learning_rate))\n",
    "        plt.show()\n",
    " \n",
    "\n",
    "    def single_example_backprop(self,x,y):\n",
    "        self.x = x\n",
    "#        \"Y-output array\"\n",
    "        self.x = Y\n",
    "#        \"Update weights\"\n",
    "        loss_list = []  #keep track of cost for every epoch\n",
    "        for epoch in range(0,100):#training for 100 epochs\n",
    "            loss = 0 #initialize loss = 0 for every epoch\n",
    "            for batch in zip(x,y):\n",
    "                X_batch, Y_batch = batch #passing the one vector of X and Y\n",
    "                X_batch, Y_batch = X_batch.reshape(1, X_batch.shape[0]), Y_batch.reshape(1, Y_batch.shape[0])\n",
    "                \n",
    "                feed_forward_op = self.feed_forward(X_batch) #getting forward propagation results\n",
    "              \n",
    "\n",
    "                AL, caches = feed_forward_op\n",
    "                \n",
    "                cost = compute_cost(AL, Y_batch)   #computing the cost from output and true output value\n",
    "                \n",
    "                grads = L_model_backward(AL, Y_batch, caches)   #calculating the gradients by back propagation\n",
    "                \n",
    "                self.parameters = update_parameters(self.parameters, grads, self.learning_rate)   #updating the weights\n",
    "                loss += cost\n",
    "                \n",
    "            print(\"loss after {} : {}\".format(epoch, loss))\n",
    "            loss_list.append(loss) #append the loss\n",
    " \n",
    "            #plotting the graph between loss and epochs\n",
    "        plt.plot(np.squeeze(loss_list))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per epoch)')\n",
    "        plt.title(\"Learning rate =\" + str(self.learning_rate))\n",
    "        plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8384727",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.randn(1, 4) #creating the dataset\n",
    "x2 = np.random.randn(1, 4)\n",
    "x3 = np.random.randn(1, 4)\n",
    "x4 = np.random.randn(1, 4)\n",
    "x5 = np.random.randn(1, 4)\n",
    "x6 = np.random.randn(1, 4)\n",
    "x7 = np.random.randn(1, 4)\n",
    "x8 = np.random.randn(1, 4)\n",
    "\n",
    "y1 = x1**2\n",
    "y2 = x2**2\n",
    "y3 = x3**2\n",
    "y4 = x4**2\n",
    "y5 = x5**2\n",
    "y6 = x6**2\n",
    "y7 = x7**2\n",
    "y8 = x8**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8442887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8), axis=0) #concatenate the X\n",
    "Y = np.concatenate((y1,y2, y3, y4, y5, y6, y7, y8), axis=0) #concatenate the Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9da6ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the X is  (8, 4)\n",
      "shape of the Y is  (8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the X is \",X.shape)\n",
    "print(\"shape of the Y is \",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc4b4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = X.shape[0]  #total number of input data points\n",
    "output_layer_size = Y.shape[1] #number of the neurons in the output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478b9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [data_points,500,600,output_layer_size] #making the input arguments in the given format\n",
    "network_new = network(arr) #passing the list and initializing the weights \n",
    "forward_pass = network_new.feed_forward(X) #calling the forward pass method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "id": "b24e58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 0 : 3.980517409588807\n",
      "loss after 1 : 1.672327113439812\n",
      "loss after 2 : 1.0249249317823437\n",
      "loss after 3 : 0.5772763831823768\n",
      "loss after 4 : 0.5037142942151538\n",
      "loss after 5 : 0.381028009361055\n",
      "loss after 6 : 0.3370962053346767\n",
      "loss after 7 : 0.3175709599987642\n",
      "loss after 8 : 0.306064617086993\n",
      "loss after 9 : 0.29913504351674725\n",
      "loss after 10 : 0.29462424229572176\n",
      "loss after 11 : 0.29115233322961126\n",
      "loss after 12 : 0.28875086066305133\n",
      "loss after 13 : 0.287081694672446\n",
      "loss after 14 : 0.2855282268553693\n",
      "loss after 15 : 0.28404889293193086\n",
      "loss after 16 : 0.28342600383189176\n",
      "loss after 17 : 0.2825767480254581\n",
      "loss after 18 : 0.2819752087759752\n",
      "loss after 19 : 0.2812874860064556\n",
      "loss after 20 : 0.28091554046442235\n",
      "loss after 21 : 0.28051493711395475\n",
      "loss after 22 : 0.2800294176329143\n",
      "loss after 23 : 0.27972142232443786\n",
      "loss after 24 : 0.27940194985894246\n",
      "loss after 25 : 0.2789243318081899\n",
      "loss after 26 : 0.2787919895034728\n",
      "loss after 27 : 0.27846135009367134\n",
      "loss after 28 : 0.27818006341680135\n",
      "loss after 29 : 0.2779022080223915\n",
      "loss after 30 : 0.2775095950613535\n",
      "loss after 31 : 0.2773488018913924\n",
      "loss after 32 : 0.2770497564332419\n",
      "loss after 33 : 0.2767243230506185\n",
      "loss after 34 : 0.27660031213455083\n",
      "loss after 35 : 0.276443505542952\n",
      "loss after 36 : 0.2762651990880444\n",
      "loss after 37 : 0.27601355882757467\n",
      "loss after 38 : 0.2759678229277266\n",
      "loss after 39 : 0.27570459889951027\n",
      "loss after 40 : 0.2755836894623255\n",
      "loss after 41 : 0.2754849367922137\n",
      "loss after 42 : 0.27536880550252796\n",
      "loss after 43 : 0.2751319737124778\n",
      "loss after 44 : 0.2750357249680675\n",
      "loss after 45 : 0.2749380868816413\n",
      "loss after 46 : 0.2748424772698101\n",
      "loss after 47 : 0.2746585996623401\n",
      "loss after 48 : 0.2745409260996172\n",
      "loss after 49 : 0.2744833816462615\n",
      "loss after 50 : 0.2743778373802962\n",
      "loss after 51 : 0.27427616710817226\n",
      "loss after 52 : 0.27411080855536396\n",
      "loss after 53 : 0.27407585320235534\n",
      "loss after 54 : 0.2739707840186793\n",
      "loss after 55 : 0.2739069532907099\n",
      "loss after 56 : 0.27381438195407826\n",
      "loss after 57 : 0.27365156569799703\n",
      "loss after 58 : 0.2736715279804271\n",
      "loss after 59 : 0.2735856857343365\n",
      "loss after 60 : 0.27347022562024403\n",
      "loss after 61 : 0.2733863348262688\n",
      "loss after 62 : 0.2733704895992732\n",
      "loss after 63 : 0.2732835840838946\n",
      "loss after 64 : 0.27321863711163574\n",
      "loss after 65 : 0.2731122013740544\n",
      "loss after 66 : 0.2731008905414579\n",
      "loss after 67 : 0.2730287933338837\n",
      "loss after 68 : 0.27299012450703025\n",
      "loss after 69 : 0.27292619753871966\n",
      "loss after 70 : 0.2728048893393498\n",
      "loss after 71 : 0.27282369168850323\n",
      "loss after 72 : 0.27275472724417443\n",
      "loss after 73 : 0.2727150381762993\n",
      "loss after 74 : 0.27265988337762254\n",
      "loss after 75 : 0.27257291614984785\n",
      "loss after 76 : 0.27255461646000767\n",
      "loss after 77 : 0.27253114877670725\n",
      "loss after 78 : 0.27249451263115104\n",
      "loss after 79 : 0.2724300353245641\n",
      "loss after 80 : 0.27236310945688597\n",
      "loss after 81 : 0.27235752157560866\n",
      "loss after 82 : 0.27232112491495675\n",
      "loss after 83 : 0.27229214059312357\n",
      "loss after 84 : 0.2722449576965097\n",
      "loss after 85 : 0.2721812052299821\n",
      "loss after 86 : 0.2721635214947213\n",
      "loss after 87 : 0.27212980109682827\n",
      "loss after 88 : 0.2720854153228891\n",
      "loss after 89 : 0.27205732853366443\n",
      "loss after 90 : 0.27202658682474246\n",
      "loss after 91 : 0.271986336250233\n",
      "loss after 92 : 0.27196351751173736\n",
      "loss after 93 : 0.27192866720374903\n",
      "loss after 94 : 0.2718833136814098\n",
      "loss after 95 : 0.27187027857533375\n",
      "loss after 96 : 0.2718305067056009\n",
      "loss after 97 : 0.27182422572723886\n",
      "loss after 98 : 0.2717866974335695\n",
      "loss after 99 : 0.2717604994411344\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_backpropagation = network_new.batch_sgd_backprop(X,Y) #training using batch_sgd_backprop method of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "4ecae109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "arr = [data_points,500,600,output_layer_size] #making the input arguments in the given format\n",
    "network_new = network(arr) #passing the list and initializing the weights \n",
    "forward_pass = network_new.feed_forward(X) #calling the forward pass method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "beba7508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 0 : 5.464193451922486\n",
      "loss after 1 : 1.0835974013866947\n",
      "loss after 2 : 0.6131414578104781\n",
      "loss after 3 : 0.4745379903695737\n",
      "loss after 4 : 0.41824957669705\n",
      "loss after 5 : 0.38949157833670944\n",
      "loss after 6 : 0.37111998384053513\n",
      "loss after 7 : 0.3587586646516038\n",
      "loss after 8 : 0.34834414606077563\n",
      "loss after 9 : 0.33914772749933314\n",
      "loss after 10 : 0.33249181365973013\n",
      "loss after 11 : 0.32605396142774823\n",
      "loss after 12 : 0.3201890668830029\n",
      "loss after 13 : 0.31542577754060375\n",
      "loss after 14 : 0.31230918703130733\n",
      "loss after 15 : 0.3088028825758887\n",
      "loss after 16 : 0.3055751165085432\n",
      "loss after 17 : 0.3032311697136546\n",
      "loss after 18 : 0.30120724132728766\n",
      "loss after 19 : 0.2991959844891921\n",
      "loss after 20 : 0.29746378832580445\n",
      "loss after 21 : 0.29607377784863165\n",
      "loss after 22 : 0.2948983373364873\n",
      "loss after 23 : 0.2935468733380672\n",
      "loss after 24 : 0.29248918623580905\n",
      "loss after 25 : 0.2915602419141918\n",
      "loss after 26 : 0.29060258830747615\n",
      "loss after 27 : 0.28979367720904486\n",
      "loss after 28 : 0.2890581402654748\n",
      "loss after 29 : 0.2883723942994005\n",
      "loss after 30 : 0.287584654160892\n",
      "loss after 31 : 0.2869058331694716\n",
      "loss after 32 : 0.2862847580344383\n",
      "loss after 33 : 0.2859405694811754\n",
      "loss after 34 : 0.2852370589687629\n",
      "loss after 35 : 0.28476594731052896\n",
      "loss after 36 : 0.28406219906897506\n",
      "loss after 37 : 0.283866929899222\n",
      "loss after 38 : 0.2834890655050558\n",
      "loss after 39 : 0.28301973687572074\n",
      "loss after 40 : 0.2826650344905978\n",
      "loss after 41 : 0.28230535166887044\n",
      "loss after 42 : 0.28187641959483695\n",
      "loss after 43 : 0.2816324769983387\n",
      "loss after 44 : 0.2813322878777761\n",
      "loss after 45 : 0.2809576345248747\n",
      "loss after 46 : 0.2806621434822541\n",
      "loss after 47 : 0.2804302561298258\n",
      "loss after 48 : 0.28006535589069037\n",
      "loss after 49 : 0.27991847873061493\n",
      "loss after 50 : 0.27963188764103114\n",
      "loss after 51 : 0.279298084552285\n",
      "loss after 52 : 0.27921836123487453\n",
      "loss after 53 : 0.27900259885381967\n",
      "loss after 54 : 0.27875354935676705\n",
      "loss after 55 : 0.27855208858194386\n",
      "loss after 56 : 0.2783884426394599\n",
      "loss after 57 : 0.27811675606496283\n",
      "loss after 58 : 0.27805588741680676\n",
      "loss after 59 : 0.27783314775113765\n",
      "loss after 60 : 0.2776848771667183\n",
      "loss after 61 : 0.2775246403745634\n",
      "loss after 62 : 0.27732126547108377\n",
      "loss after 63 : 0.27718777142541207\n",
      "loss after 64 : 0.27707446136601643\n",
      "loss after 65 : 0.2769185612221132\n",
      "loss after 66 : 0.2767490475655711\n",
      "loss after 67 : 0.27661697913505706\n",
      "loss after 68 : 0.27651930648099526\n",
      "loss after 69 : 0.2764082090660331\n",
      "loss after 70 : 0.27625316440525455\n",
      "loss after 71 : 0.2761503373521297\n",
      "loss after 72 : 0.2760435009020589\n",
      "loss after 73 : 0.27591919899689443\n",
      "loss after 74 : 0.27579727736119325\n",
      "loss after 75 : 0.27571874470026614\n",
      "loss after 76 : 0.27555378069155995\n",
      "loss after 77 : 0.27552352656596174\n",
      "loss after 78 : 0.27542074005388206\n",
      "loss after 79 : 0.2753337817865232\n",
      "loss after 80 : 0.2751898948673718\n",
      "loss after 81 : 0.27515383440853464\n",
      "loss after 82 : 0.27505421036742106\n",
      "loss after 83 : 0.2749587239748699\n",
      "loss after 84 : 0.27489260697784645\n",
      "loss after 85 : 0.27479070614318535\n",
      "loss after 86 : 0.2747420629255082\n",
      "loss after 87 : 0.2746611229626747\n",
      "loss after 88 : 0.2745857834860286\n",
      "loss after 89 : 0.2745177851689561\n",
      "loss after 90 : 0.27444517437204047\n",
      "loss after 91 : 0.2743684885544939\n",
      "loss after 92 : 0.27429143824028107\n",
      "loss after 93 : 0.27425171625351835\n",
      "loss after 94 : 0.27417346780906543\n",
      "loss after 95 : 0.2741373141428272\n",
      "loss after 96 : 0.2740715331642408\n",
      "loss after 97 : 0.2740052846300427\n",
      "loss after 98 : 0.2739620226006755\n",
      "loss after 99 : 0.2738929319947261\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_backpropagation = network_new.single_example_backprop(X,Y) #training using single_example_backprop method of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "id": "fff492ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass = network_new.feed_forward(X) #testing using same input and forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "id": "b4cdfad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18327425, 0.32233094, 1.41507904, 0.4976472 ],\n",
       "       [0.59371621, 0.33964942, 1.61142202, 1.10644708],\n",
       "       [1.76792441, 0.        , 0.004842  , 2.21255543],\n",
       "       [0.63562333, 0.02448867, 0.29244979, 0.05512703],\n",
       "       [0.11708463, 0.22871245, 1.04051129, 1.09230261],\n",
       "       [1.8703168 , 0.5117353 , 0.        , 1.97590546],\n",
       "       [1.33498126, 3.18337686, 0.04676933, 0.        ],\n",
       "       [0.80127666, 0.2265875 , 0.79707153, 0.80648416]])"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "id": "1d6c7020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18574581, 0.32358361, 1.41397421, 0.49621066],\n",
       "       [0.55745554, 0.32228346, 1.6372529 , 1.11809751],\n",
       "       [1.76766375, 0.031297  , 0.00528467, 2.21268719],\n",
       "       [0.62156476, 0.01821452, 0.30592892, 0.05512306],\n",
       "       [0.11542194, 0.22798207, 1.04197003, 1.09291071],\n",
       "       [1.8642064 , 0.5113272 , 1.47201267, 1.97652977],\n",
       "       [1.33535055, 3.18363107, 0.04641874, 0.00702173],\n",
       "       [0.82547619, 0.24321644, 0.78110122, 0.79788594]])"
      ]
     },
     "execution_count": 1174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "d0a2c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.square(forward_pass[0] - Y).mean() #error for the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "id": "19345339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error is : 0.06787295498749263\n"
     ]
    }
   ],
   "source": [
    "print(\"error is : {}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3659415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb217244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b174308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
